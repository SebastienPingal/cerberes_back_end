name: AWS Deployment Pipeline

on:
  push:
    branches: [ master ]
  workflow_run:
    workflows: ["CI Pipeline"]
    branches: [master]
    types:
      - completed

jobs:
  deploy:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'push' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      # Debug step to check secrets are available (values will be masked)
      - name: Debug Secret Presence
        run: |
          if [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ]; then 
            echo "AWS_ACCESS_KEY_ID is set ✅"
          else
            echo "AWS_ACCESS_KEY_ID is NOT set ❌"
          fi
          
          if [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then 
            echo "AWS_SECRET_ACCESS_KEY is set ✅"
          else
            echo "AWS_SECRET_ACCESS_KEY is NOT set ❌"  
          fi
          
          if [ -n "${{ secrets.AWS_REGION }}" ]; then 
            echo "AWS_REGION is set ✅"
          else
            echo "AWS_REGION is NOT set ❌"
          fi

      # Build the app directly instead of trying to download an artifact
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8.6.0

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 16
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Build application
        run: pnpm build

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Create terraform.tfvars
        run: |
          cat > terraform/terraform.tfvars << EOF
          aws_region      = "${{ secrets.AWS_REGION }}"
          app_name        = "cerberes"
          db_username     = "${{ secrets.DB_USERNAME }}"
          db_password     = "${{ secrets.DB_PASSWORD }}"
          ssh_key_name    = "${{ secrets.SSH_KEY_NAME }}"
          ec2_instance_type = "t2.micro"
          db_instance_class = "db.t3.micro"
          EOF
          
          echo "🔑 Created terraform.tfvars with database credentials"

      # Check for existing resources and modify Terraform code accordingly
      - name: Check for existing resources
        id: check-resources
        run: |
          # Get the default VPC ID for security group checks
          DEFAULT_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --query "Vpcs[0].VpcId" --output text)
          echo "DEFAULT_VPC_ID=$DEFAULT_VPC_ID" >> $GITHUB_ENV
          
          # Check if we have existing VPCs
          VPC_COUNT=$(aws ec2 describe-vpcs --query "length(Vpcs)" --output text)
          
          if [ "$VPC_COUNT" -gt "0" ]; then
            echo "VPC_EXISTS=true" >> $GITHUB_ENV
            echo "✅ VPCs exist - will use existing ones"
            # Modify the Terraform code to use existing VPCs
            sed -i '/data "aws_vpcs" "existing" {/,/count =/ s/count = 0/count = 1/g' terraform/main.tf
          else
            echo "VPC_EXISTS=false" >> $GITHUB_ENV
            echo "🆕 No VPCs exist - will use default VPC"
          fi
          
          # Check if EC2 security group exists
          if aws ec2 describe-security-groups --filters "Name=group-name,Values=cerberes-ec2-sg" "Name=vpc-id,Values=$DEFAULT_VPC_ID" --query "SecurityGroups[0].GroupId" --output text &> /dev/null; then
            echo "EC2_SG_EXISTS=true" >> $GITHUB_ENV
            echo "✅ EC2 Security Group exists - will use existing one"
            # Modify the Terraform code to use the existing security group
            sed -i '/data "aws_security_group" "ec2_existing" {/,/count =/ s/count = 0/count = 1/g' terraform/ec2.tf
          else
            echo "EC2_SG_EXISTS=false" >> $GITHUB_ENV
            echo "🆕 EC2 Security Group does not exist - will create new one"
          fi
          
          # Check if DB security group exists
          if aws ec2 describe-security-groups --filters "Name=group-name,Values=cerberes-db-sg" "Name=vpc-id,Values=$DEFAULT_VPC_ID" --query "SecurityGroups[0].GroupId" --output text &> /dev/null; then
            echo "DB_SG_EXISTS=true" >> $GITHUB_ENV
            echo "✅ DB Security Group exists - will use existing one"
            # Modify the Terraform code to use the existing security group
            sed -i '/data "aws_security_group" "db_existing" {/,/count =/ s/count = 0/count = 1/g' terraform/rds.tf
          else
            echo "DB_SG_EXISTS=false" >> $GITHUB_ENV
            echo "🆕 DB Security Group does not exist - will create new one"
          fi
          
          # Check if EC2 instances with the tag Name=cerberes-instance exist
          EC2_COUNT=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=cerberes-instance" "Name=instance-state-name,Values=running,stopped" --query "length(Reservations[*].Instances[*])" --output text)
          
          if [ "$EC2_COUNT" -gt "0" ]; then
            echo "EC2_INSTANCE_EXISTS=true" >> $GITHUB_ENV
            EC2_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=cerberes-instance" "Name=instance-state-name,Values=running,stopped" --query "Reservations[0].Instances[0].InstanceId" --output text)
            echo "✅ EC2 Instance exists - will use existing one: $EC2_ID"
            # Modify the Terraform code to use the existing EC2 instance
            sed -i '/data "aws_instances" "existing" {/,/count =/ s/count = 0/count = 1/g' terraform/ec2.tf
          else
            echo "EC2_INSTANCE_EXISTS=false" >> $GITHUB_ENV
            echo "🆕 EC2 Instance does not exist - will create new one"
          fi
          
          # Check if DB subnet group exists
          if aws rds describe-db-subnet-groups --db-subnet-group-name cerberes-db-subnet-group &> /dev/null; then
            echo "SUBNET_GROUP_EXISTS=true" >> $GITHUB_ENV
            echo "✅ DB Subnet Group exists - will use existing one"
            # Modify the Terraform code to use the existing subnet group
            sed -i '/data "aws_db_subnet_group" "existing" {/,/count =/ s/count = 0/count = 1/g' terraform/rds.tf
          else
            echo "SUBNET_GROUP_EXISTS=false" >> $GITHUB_ENV
            echo "🆕 DB Subnet Group does not exist - will create new one"
          fi
          
          # Check if DB instance exists
          if aws rds describe-db-instances --db-instance-identifier cerberes-db &> /dev/null; then
            echo "DB_INSTANCE_EXISTS=true" >> $GITHUB_ENV
            echo "✅ DB Instance exists - will use existing one"
            # Modify the Terraform code to use the existing DB instance
            sed -i '/data "aws_db_instance" "existing" {/,/count =/ s/count = 0/count = 1/g' terraform/rds.tf
          else
            echo "DB_INSTANCE_EXISTS=false" >> $GITHUB_ENV
            echo "🆕 DB Instance does not exist - will create new one"
          fi

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Plan
        working-directory: ./terraform
        run: terraform plan -out=tfplan

      - name: Terraform Apply
        id: terraform-apply
        working-directory: ./terraform
        run: terraform apply -auto-approve tfplan

      - name: Get EC2 public IP
        if: steps.terraform-apply.outcome == 'success'
        working-directory: ./terraform
        id: ec2_ip
        run: |
          # Get the IP address using a simpler approach
          IP_ADDRESS=$(terraform output -raw public_ip | tr -d '\n')
          # Set the output using the newer approach
          echo "ip=$IP_ADDRESS" >> $GITHUB_OUTPUT
          echo "🖥️ EC2 instance public IP: $IP_ADDRESS"

      # Get RDS endpoint for database connection
      - name: Get RDS endpoint
        if: steps.terraform-apply.outcome == 'success'
        working-directory: ./terraform
        id: rds_endpoint
        run: |
          # Get the RDS endpoint using a simpler approach
          DB_ENDPOINT=$(terraform output -raw db_endpoint | tr -d '\n')
          # Set the output using the newer approach
          echo "endpoint=$DB_ENDPOINT" >> $GITHUB_OUTPUT
          echo "🗄️ RDS endpoint: $DB_ENDPOINT"

      # Add a delay to ensure EC2 instance is fully initialized
      - name: Wait for EC2 instance to initialize
        if: steps.terraform-apply.outcome == 'success'
        run: |
          echo "⏳ Waiting 60 seconds for EC2 instance to fully initialize..."
          sleep 60

      - name: Deploy application to EC2
        if: steps.terraform-apply.outcome == 'success'
        uses: appleboy/scp-action@master
        with:
          host: ${{ steps.ec2_ip.outputs.ip }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          source: "dist/,package.json,pnpm-lock.yaml,.env"
          target: "/home/ec2-user/app"

      - name: Configure and start application
        if: steps.terraform-apply.outcome == 'success'
        uses: appleboy/ssh-action@master
        with:
          host: ${{ steps.ec2_ip.outputs.ip }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          script: |
            cd /home/ec2-user/app
            
            # Add production environment variables
            cat > .env << EOF
            NODE_ENV=production
            DATABASE_URL=postgres://${{ secrets.DB_USERNAME }}:${{ secrets.DB_PASSWORD }}@${{ steps.rds_endpoint.outputs.endpoint }}/cerberes
            PORT=3000
            EOF
            
            # Install dependencies and start with PM2
            pnpm install --prod
            pm2 stop cerberes || echo "🤖 App not running"
            pm2 start dist/src/server.js --name cerberes
            pm2 save
            
            echo "🚀 Deployment completed"
            
      - name: Cleanup on failure
        if: failure() && steps.terraform-apply.outcome == 'failure'
        working-directory: ./terraform
        run: |
          echo "🧹 Cleaning up failed deployment..."
          terraform destroy -auto-approve
          echo "♻️ Resources cleaned up."
